{"cells":[{"cell_type":"markdown","source":["# Actividad 1b: Implementación de Red Neuronal Profunda (ASL Dataset)\n","**Curso:** TC 5033 - Deep Learning\n","\n","**Equipo:**\n","1. Brenda Flores Peralta, A01366533\n","2. Juan Carlos Gaibor Valencia, A01684174\n","3. Daniel Gámez Serna, A\n","4. Javier Emmanuel García Escobedo, A01411206\n"],"metadata":{"id":"FLq_BBX2O-nw"}},{"cell_type":"markdown","metadata":{"id":"RX_ZQ7EW8l6r"},"source":["# TC 5033\n","## Deep Learning\n","## Fully Connected Deep Neural Networks\n","\n","#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n","\n","- Objective\n","\n","The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n","\n","- Instructions\n","\n","    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n","\n","    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n","\n","    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n","\n","    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n","\n","    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n","    \n","     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n","\n","    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n","\n","    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n","\n","- Evaluation Criteria\n","\n","    - Code Readability and Comments\n","    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n","    - Performance of the model on the ASL dataset (at least 70% acc)\n","    - Quality of Markdown documentation\n","\n","- Submission\n","\n","Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euA7dn0T8l6s"},"outputs":[],"source":["import numpy as np\n","import string\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2 as cv\n","import os\n","\n","\n","#################################\n","%matplotlib inline"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"RyEXIUMz90w2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770002847463,"user_tz":300,"elapsed":896,"user":{"displayName":"Juan Carlos Gaibor","userId":"16350272554692264517"}},"outputId":"875b2408-6221-4f69-e9c1-29e4d60d71cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2nhNriO8l6s"},"outputs":[],"source":["DATA_PATH = \"/content/drive/My Drive/Maestria de Inteligencia Artificial Aplicada/Advanced Machine Learning Methods/semana 2/asl_data/\"\n","train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n","valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mvomJ5K8l6t","colab":{"base_uri":"https://localhost:8080/","height":236},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1770002851063,"user_tz":300,"elapsed":24,"user":{"displayName":"Juan Carlos Gaibor","userId":"16350272554692264517"}},"outputId":"6a8ea897-21c3-42ac-bdd1-6fc87b203805"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n","0      3     107     118     127     134     139     143     146     150   \n","1      6     155     157     156     156     156     157     156     158   \n","2      2     187     188     188     187     187     186     187     188   \n","3      2     211     211     212     212     211     210     211     210   \n","4     12     164     167     170     172     176     179     180     184   \n","\n","   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n","0     153  ...       207       207       207       207       206       206   \n","1     158  ...        69       149       128        87        94       163   \n","2     187  ...       202       201       200       199       198       199   \n","3     210  ...       235       234       233       231       230       226   \n","4     185  ...        92       105       105       108       133       163   \n","\n","   pixel781  pixel782  pixel783  pixel784  \n","0       206       204       203       202  \n","1       175       103       135       149  \n","2       198       195       194       195  \n","3       225       222       229       163  \n","4       157       163       164       179  \n","\n","[5 rows x 785 columns]"],"text/html":["\n","  <div id=\"df-a24eec2e-544c-4247-a938-4dd0dbadf4a4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>pixel9</th>\n","      <th>...</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","      <th>pixel784</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>107</td>\n","      <td>118</td>\n","      <td>127</td>\n","      <td>134</td>\n","      <td>139</td>\n","      <td>143</td>\n","      <td>146</td>\n","      <td>150</td>\n","      <td>153</td>\n","      <td>...</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>207</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>206</td>\n","      <td>204</td>\n","      <td>203</td>\n","      <td>202</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>155</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>156</td>\n","      <td>157</td>\n","      <td>156</td>\n","      <td>158</td>\n","      <td>158</td>\n","      <td>...</td>\n","      <td>69</td>\n","      <td>149</td>\n","      <td>128</td>\n","      <td>87</td>\n","      <td>94</td>\n","      <td>163</td>\n","      <td>175</td>\n","      <td>103</td>\n","      <td>135</td>\n","      <td>149</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>187</td>\n","      <td>188</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>187</td>\n","      <td>186</td>\n","      <td>187</td>\n","      <td>188</td>\n","      <td>187</td>\n","      <td>...</td>\n","      <td>202</td>\n","      <td>201</td>\n","      <td>200</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>199</td>\n","      <td>198</td>\n","      <td>195</td>\n","      <td>194</td>\n","      <td>195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>211</td>\n","      <td>211</td>\n","      <td>212</td>\n","      <td>212</td>\n","      <td>211</td>\n","      <td>210</td>\n","      <td>211</td>\n","      <td>210</td>\n","      <td>210</td>\n","      <td>...</td>\n","      <td>235</td>\n","      <td>234</td>\n","      <td>233</td>\n","      <td>231</td>\n","      <td>230</td>\n","      <td>226</td>\n","      <td>225</td>\n","      <td>222</td>\n","      <td>229</td>\n","      <td>163</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>12</td>\n","      <td>164</td>\n","      <td>167</td>\n","      <td>170</td>\n","      <td>172</td>\n","      <td>176</td>\n","      <td>179</td>\n","      <td>180</td>\n","      <td>184</td>\n","      <td>185</td>\n","      <td>...</td>\n","      <td>92</td>\n","      <td>105</td>\n","      <td>105</td>\n","      <td>108</td>\n","      <td>133</td>\n","      <td>163</td>\n","      <td>157</td>\n","      <td>163</td>\n","      <td>164</td>\n","      <td>179</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 785 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a24eec2e-544c-4247-a938-4dd0dbadf4a4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a24eec2e-544c-4247-a938-4dd0dbadf4a4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a24eec2e-544c-4247-a938-4dd0dbadf4a4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df"}},"metadata":{},"execution_count":176}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"VQYi6VR_8l6t"},"source":["### Importar Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnPhr5mj8l6t"},"outputs":[],"source":["y_train = np.array(train_df['label'])\n","y_val = np.array(valid_df['label'])\n","del train_df['label']\n","del valid_df['label']\n","x_train = train_df.values.astype(np.float32)\n","x_val = valid_df.values.astype(np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[],"id":"_w7TI9618l6t"},"outputs":[],"source":["def split_val_test(x, y, pct=0.5, shuffle=True):\n","    if shuffle:\n","        indices = np.arange(len(y))\n","        np.random.shuffle(indices)\n","        x = x[indices]\n","        y = y[indices]\n","\n","    split_idx = int(len(y) * (1 - pct))\n","    x_val, x_test = x[:split_idx], x[split_idx:]\n","    y_val, y_test = y[:split_idx], y[split_idx:]\n","\n","    return x_val, y_val, x_test, y_test\n","\n","# Ejecutar la división\n","x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okkAEwLu8l6t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770002851387,"user_tz":300,"elapsed":10,"user":{"displayName":"Juan Carlos Gaibor","userId":"16350272554692264517"}},"outputId":"d0b16828-c3d6-4a9a-d128-cb9a4eb16554"},"outputs":[{"output_type":"stream","name":"stdout","text":["24\n"]}],"source":["### The following\n","\n","alphabet=list(string.ascii_lowercase)\n","alphabet.remove('j')\n","alphabet.remove('z')\n","print(len(alphabet))"]},{"cell_type":"markdown","metadata":{"id":"--mhBcpb8l6t"},"source":["### Normalise"]},{"cell_type":"code","source":["x_train /= 255.0\n","x_val /= 255.0\n","x_test /= 255.0"],"metadata":{"id":"wK0jpISF_ogI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2hRodpXn8l6u"},"source":["### Graficar muestras"]},{"cell_type":"code","source":["def plot_number(image):\n","    \"\"\"Grafica una sola imagen de 28x28.\"\"\"\n","    plt.imshow(image, cmap='gray')\n","    plt.axis('off')\n","\n","def plot_samples(X, y, alphabet, n=10):\n","    \"\"\"Grafica una fila de n muestras aleatorias con sus letras correspondientes.\"\"\"\n","    plt.figure(figsize=(15, 3))\n","    for i in range(n):\n","        idx = np.random.randint(0, len(X))\n","        plt.subplot(1, n, i + 1)\n","        # Cambiamos la forma de 784 a 28x28 para visualizar\n","        plt.imshow(X[idx].reshape(28, 28), cmap='gray')\n","        # Mostramos la letra correspondiente del alfabeto\n","        plt.title(alphabet[y[idx]])\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.savefig('muestras_asl.png') # Guarda la imagen para referencia\n","    plt.show()\n","\n","# Llamada a la función para visualizar 10 muestras del set de entrenamiento\n","plot_samples(x_train, y_train, alphabet)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"id":"_2hviDAl_v-D","executionInfo":{"status":"ok","timestamp":1770002852384,"user_tz":300,"elapsed":971,"user":{"displayName":"Juan Carlos Gaibor","userId":"16350272554692264517"}},"outputId":"4e9884be-be35-48ce-bbf1-b95c9e19482b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x300 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"3RHLVPTc8l6u"},"source":["### Ecuaciones para nuestro modelo\n","\n","\n","$$z^1 = W^1 X + b^1$$\n","\n","$$a^1 = ReLU(z^1) $$\n","\n","$$z^2 = W^2 a^1 + b^2$$\n","\n","$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n","\n","\n","$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n","\n","\n","$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"]},{"cell_type":"markdown","metadata":{"id":"1DMdo3Uo8l6u"},"source":["### Funciones adicionales"]},{"cell_type":"markdown","metadata":{"id":"-AbJMhvb8l6u"},"source":["#### Mini batches"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JSy8ZcJ8l6u"},"outputs":[],"source":["def create_minibatches(X, y, batch_size, shuffle=True):\n","    \"\"\"\n","    Genera una lista de mini-batches a partir de X e y.\n","\n","    Argumentos:\n","    X -- Matriz de datos de entrada (muestras, características)\n","    y -- Vector de etiquetas\n","    batch_size -- Tamaño de cada lote\n","    shuffle -- Si es True, mezcla los datos antes de dividir\n","\n","    Retorna:\n","    list -- Una lista de tuplas (X_mini, y_mini)\n","    \"\"\"\n","    m = X.shape[0]\n","    minibatches = []\n","\n","    # 1. Mezclar (Shuffle) los datos\n","    if shuffle:\n","        indices = np.arange(m)\n","        np.random.shuffle(indices)\n","        X = X[indices]\n","        y = y[indices]\n","\n","    # 2. Dividir en lotes (Partition)\n","    n_minibatches = m // batch_size\n","\n","    for i in range(n_minibatches):\n","        X_mini = X[i * batch_size : (i + 1) * batch_size]\n","        y_mini = y[i * batch_size : (i + 1) * batch_size]\n","        minibatches.append((X_mini, y_mini))\n","\n","    # 3. Manejar el caso donde el total de muestras no es divisible por batch_size\n","    if m % batch_size != 0:\n","        X_mini = X[n_minibatches * batch_size : ]\n","        y_mini = y[n_minibatches * batch_size : ]\n","        minibatches.append((X_mini, y_mini))\n","\n","    return minibatches"]},{"cell_type":"markdown","metadata":{"id":"NJqbAy4Q8l6u"},"source":["## Nuestra clase Linear, ReLU y Sequential"]},{"cell_type":"markdown","metadata":{"id":"myhbiktB8l6u"},"source":["###  Clase Linear"]},{"cell_type":"code","source":["class Linear():\n","    def __init__(self, input_size, output_size):\n","        # Constructor de la capa Linear.\n","        # input_size: número de características de entrada.\n","        # output_size: número de neuronas de salida en esta capa.\n","\n","        # Inicialización de He para los pesos (W) para ayudar a mitigar el problema del gradiente que desaparece/explota.\n","        # Los pesos se inicializan con una distribución normal escalada.\n","        self.W = np.random.randn(output_size, input_size) * np.sqrt(2./input_size)\n","        # Los sesgos (b) se inicializan a cero. 'output_size' filas y 1 columna.\n","        self.b = np.zeros((output_size, 1))\n","\n","    def __call__(self, x):\n","        # Implementa la pasada hacia adelante (forward pass) de la capa Linear.\n","        # x: entrada a la capa, de forma (input_size, batch_size).\n","\n","        # Guardamos la entrada 'x' para usarla en el cálculo del gradiente durante el backward pass.\n","        self.x = x # Guardamos para el backprop\n","        # Realiza la operación lineal: Z = W * X + b.\n","        # np.dot(self.W, x): multiplicación de la matriz de pesos con la matriz de entrada.\n","        # self.b: el vector de sesgos se suma a cada columna del resultado anterior (broadcasting).\n","        return np.dot(self.W, x) + self.b\n","\n","    def backward(self, grad_output, lr):\n","        # Implementa la pasada hacia atrás (backward pass) de la capa Linear.\n","        # grad_output: gradiente de la función de pérdida con respecto a la salida de esta capa (dL/dZ).\n","        # lr: learning rate (tasa de aprendizaje) para la actualización de los pesos y sesgos.\n","\n","        # Número de muestras en el mini-batch.\n","        m = self.x.shape[1]\n","\n","        # Cálculo del gradiente de la función de pérdida con respecto a los pesos (dL/dW).\n","        # dL/dW = grad_output * x.T (dL/dZ * X_transpuesta).\n","        dw = np.dot(grad_output, self.x.T) / m\n","\n","        # Cálculo del gradiente de la función de pérdida con respecto a los sesgos (dL/db).\n","        # dL/db = suma de grad_output a lo largo del eje de las muestras.\n","        db = np.sum(grad_output, axis=1, keepdims=True) / m\n","\n","        # Cálculo del gradiente de la función de pérdida con respecto a la entrada de esta capa (dL/dX).\n","        # Este gradiente se pasa a la capa anterior.\n","        # dL/dX = W.T * grad_output (W_transpuesta * dL/dZ).\n","        grad_input = np.dot(self.W.T, grad_output)\n","\n","        # Actualización de pesos y sesgos utilizando el Descenso de Gradiente Estocástico (SGD).\n","        # Los pesos y sesgos se ajustan en la dirección opuesta a su gradiente.\n","        self.W -= lr * dw\n","        self.b -= lr * db\n","\n","        # Devuelve el gradiente con respecto a la entrada para la propagación hacia atrás a la capa anterior.\n","        return grad_input"],"metadata":{"id":"t6p9Cd4xA6xT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAGp0YLy8l6u"},"source":["### Clase ReLU"]},{"cell_type":"code","source":["class ReLU():\n","    def __call__(self, x):\n","        # Implementa la pasada hacia adelante (forward pass) de la función de activación ReLU.\n","        # ReLU(x) = max(0, x).\n","        # x: entrada a la función ReLU.\n","\n","        # Guardamos la entrada 'x' para usarla en el cálculo del gradiente durante el backward pass.\n","        self.x = x\n","        return np.maximum(0, x)\n","\n","    def backward(self, grad_output, lr):\n","        # Implementa la pasada hacia atrás (backward pass) de la función de activación ReLU.\n","        # grad_output: gradiente de la función de pérdida con respecto a la salida de ReLU (dL/dA).\n","        # lr: learning rate (no se usa directamente aquí, ya que ReLU no tiene parámetros entrenables).\n","\n","        # El gradiente de ReLU es 1 si x > 0 y 0 si x <= 0.\n","        # Multiplicamos el gradiente de salida por una máscara booleana (x > 0) para propagar el gradiente solo donde la entrada fue positiva.\n","        # La variable 'lr' se incluye por consistencia con otras funciones 'backward' pero no afecta a la ReLU.\n","        return grad_output * (self.x > 0)"],"metadata":{"id":"eR7WltK9BDLV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h_KgW83E8l6u"},"source":["### Clase Sequential"]},{"cell_type":"code","source":["class Sequential():\n","    def __init__(self, layers):\n","        # Constructor de la clase Sequential.\n","        # layers: Una lista de objetos capa (Linear, ReLU, etc.) que componen la red.\n","        self.layers = layers\n","\n","    def __call__(self, x):\n","        # Realiza la pasada hacia adelante (forward pass) a través de todas las capas de la red.\n","        # x: La entrada inicial a la primera capa de la secuencia.\n","\n","        # Itera sobre cada capa en el orden definido y pasa la salida de una capa como entrada a la siguiente.\n","        for layer in self.layers:\n","            x = layer(x)\n","        # La salida final es el resultado de la última capa.\n","        return x\n","\n","    def backward(self, grad_output, lr):\n","        # Realiza la pasada hacia atrás (backward pass) a través de todas las capas de la red en orden inverso.\n","        # grad_output: El gradiente inicial de la función de pérdida con respecto a la salida final de la red.\n","        # lr: La tasa de aprendizaje que se pasará a los métodos backward de las capas individuales para la actualización de pesos.\n","\n","        # Itera sobre las capas en orden inverso para propagar el gradiente desde la salida hacia la entrada.\n","        for layer in reversed(self.layers):\n","            grad_output = layer.backward(grad_output, lr)\n","        # El gradiente de entrada final se propaga a través de la primera capa.\n","        return grad_output\n","\n","    def predict(self, x):\n","        # Realiza una predicción para una o varias muestras de entrada.\n","        # x: La entrada(s) para las cuales se desea hacer una predicción (puede ser una sola muestra o un batch).\n","\n","        # Realiza el forward pass para obtener los logits (salidas sin normalizar de la última capa).\n","        logits = self.__call__(x)\n","        # Aplica la función softmax para convertir los logits en probabilidades.\n","        probs = softmax(logits)\n","        # Obtiene el índice de la clase con la probabilidad más alta para cada muestra.\n","        preds = np.argmax(probs, axis=0)\n","        # Si la entrada fue una sola muestra, devuelve el escalar correspondiente. De lo contrario, devuelve el array de predicciones.\n","        return preds.item() if preds.size == 1 else preds"],"metadata":{"id":"Evz_T0lMBHrx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWE-4d9I8l6u"},"source":["### Cost Function"]},{"cell_type":"code","source":["def softmax(x):\n","    # Estabilidad numérica: restamos el máximo de cada columna\n","    exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n","    return exp_x / np.sum(exp_x, axis=0, keepdims=True)\n","\n","def cross_entropy(y_pred, y_true):\n","    # y_pred: (n_clases, batch_size), y_true: (batch_size,)\n","    m = y_true.shape[0]\n","    # Pequeño epsilon para evitar log(0)\n","    loss = -np.sum(np.log(y_pred[y_true, np.arange(m)] + 1e-10)) / m\n","    return loss"],"metadata":{"id":"IyZM7FTWBXg3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LbqAzrUq8l6u"},"source":["### Loop de entrenamiento"]},{"cell_type":"code","metadata":{"id":"czysQk6TWJXA"},"source":["def train(model, epochs, lr, x_train, y_train, x_val, y_val, batch_size=32):\n","    # Función de entrenamiento para el modelo de red neuronal.\n","    # model: La instancia de la clase Sequential que representa la red neuronal.\n","    # epochs: Número de veces que se recorrerá todo el conjunto de datos de entrenamiento.\n","    # lr: Tasa de aprendizaje para la actualización de los pesos.\n","    # x_train, y_train: Datos y etiquetas de entrenamiento.\n","    # x_val, y_val: Datos y etiquetas de validación para monitorear el rendimiento.\n","    # batch_size: Tamaño de los mini-batches para el entrenamiento.\n","\n","    for epoch in range(epochs):\n","        train_loss = 0\n","        # Crea mini-batches a partir de los datos de entrenamiento para iterar sobre ellos.\n","        minibatches = create_minibatches(x_train, y_train, batch_size)\n","\n","        for x_mini, y_mini in minibatches:\n","            # 1. Forward Pass:\n","            # Transpone x_mini para que tenga la forma (features, batch_size),\n","            # que es el formato esperado por las capas Linear.\n","            logits = model(x_mini.T)\n","            # Aplica la función softmax para obtener las probabilidades de clase.\n","            probs = softmax(logits)\n","\n","            # 2. Cálculo de la Pérdida (Loss):\n","            # Calcula la pérdida de entropía cruzada para el mini-batch actual\n","            # y la acumula para el cálculo del promedio de pérdida de la época.\n","            train_loss += cross_entropy(probs, y_mini)\n","\n","            # 3. Backward Pass:\n","            # Obtiene el número de muestras en el mini-batch actual.\n","            m_mini = y_mini.shape[0]\n","\n","            # Crea una representación one-hot de las etiquetas verdaderas para calcular el gradiente de la pérdida.\n","            y_one_hot = np.zeros_like(probs)\n","            # Establece 1 en la posición de la clase verdadera para cada muestra.\n","            y_one_hot[y_mini, np.arange(m_mini)] = 1\n","\n","            # Calcula el gradiente de la función de pérdida con respecto a los logits.\n","            # Para la entropía cruzada y softmax, esto es (P - Y_one_hot).\n","            grad_logits = (probs - y_one_hot)\n","\n","            # Realiza la retropropagación a través del modelo para calcular gradientes\n","            # y actualizar los pesos de todas las capas.\n","            model.backward(grad_logits, lr)\n","\n","        # Validación al final de cada época:\n","        # Realiza un forward pass en todo el conjunto de validación.\n","        val_probs = softmax(model(x_val.T))\n","        # Obtiene las predicciones eligiendo la clase con la mayor probabilidad.\n","        val_preds = np.argmax(val_probs, axis=0)\n","        # Calcula la precisión de validación comparando las predicciones con las etiquetas reales.\n","        val_acc = np.mean(val_preds == y_val)\n","\n","        # Imprime el progreso de entrenamiento para la época actual.\n","        print(f\"Epoch {epoch+1}/{epochs} - Loss: {train_loss/len(minibatches):.4f} - Val Acc: {val_acc:.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"THn3nEXe8l6u"},"source":["### Create your model and train it"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddA4TuFh8l6u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770002895204,"user_tz":300,"elapsed":42759,"user":{"displayName":"Juan Carlos Gaibor","userId":"16350272554692264517"}},"outputId":"e1696391-dd65-4d88-988f-9e0bf23306ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20 - Loss: 2.7246 - Val Acc: 0.3385\n","Epoch 2/20 - Loss: 1.9416 - Val Acc: 0.3645\n","Epoch 3/20 - Loss: 1.5414 - Val Acc: 0.4685\n","Epoch 4/20 - Loss: 1.2180 - Val Acc: 0.6252\n","Epoch 5/20 - Loss: 0.9725 - Val Acc: 0.4364\n","Epoch 6/20 - Loss: 0.8501 - Val Acc: 0.6933\n","Epoch 7/20 - Loss: 1.0098 - Val Acc: 0.6272\n","Epoch 8/20 - Loss: 0.6924 - Val Acc: 0.6921\n","Epoch 9/20 - Loss: 0.5534 - Val Acc: 0.7384\n","Epoch 10/20 - Loss: 0.3334 - Val Acc: 0.7808\n","Epoch 11/20 - Loss: 0.3325 - Val Acc: 0.6746\n","Epoch 12/20 - Loss: 0.3458 - Val Acc: 0.6941\n","Epoch 13/20 - Loss: 0.1905 - Val Acc: 0.7911\n","Epoch 14/20 - Loss: 0.4837 - Val Acc: 0.2839\n","Epoch 15/20 - Loss: 0.3717 - Val Acc: 0.7828\n","Epoch 16/20 - Loss: 0.3112 - Val Acc: 0.7906\n","Epoch 17/20 - Loss: 0.3677 - Val Acc: 0.8045\n","Epoch 18/20 - Loss: 0.2411 - Val Acc: 0.7817\n","Epoch 19/20 - Loss: 0.0222 - Val Acc: 0.7881\n","Epoch 20/20 - Loss: 0.0129 - Val Acc: 0.7939\n"]}],"source":["\n","# Parámetros\n","input_size = 784 # 28x28 píxeles\n","hidden1 = 128\n","hidden2 = 64\n","output_size = 24\n","learning_rate = 0.1\n","epochs = 20\n","batch_size = 64\n","\n","# Instanciar modelo\n","model = Sequential([\n","    Linear(input_size, hidden1),\n","    ReLU(),\n","    Linear(hidden1, hidden2),\n","    ReLU(),\n","    Linear(hidden2, output_size)\n","])\n","\n","# Entrenar\n","train(model, epochs, learning_rate, x_train, y_train, x_val, y_val, batch_size)"]},{"cell_type":"markdown","metadata":{"id":"uYqHUhQoW0FX"},"source":["## Arquitectura de la Red Neuronal\n","\n","La red neuronal implementada es una Red Neuronal Profunda (DNN) completamente conectada, diseñada para la clasificación de imágenes del dataset ASL. A continuación, se detalla su estructura:\n","\n","*   **Capa de Entrada (`input_size`):**\n","    *   **Tamaño:** 784 neuronas.\n","    *   **Justificación:** Cada imagen en el dataset ASL tiene una resolución de 28x28 píxeles. Dado que la entrada a nuestra red es una versión aplanada (flattened) de la imagen, `28 * 28 = 784` píxeles, donde cada píxel representa una característica de entrada. La normalización a un rango de [0, 1] se aplica para asegurar que todas las características tengan escalas similares, lo que mejora la estabilidad y velocidad del entrenamiento.\n","\n","*   **Primera Capa Oculta (`hidden1`):**\n","    *   **Tamaño:** 128 neuronas.\n","    *   **Justificación:** Se eligió un tamaño de 128 neuronas para esta capa oculta como un compromiso entre la capacidad del modelo y la complejidad computacional. Un número mayor de neuronas permitiría a la red aprender patrones más complejos, pero también aumentaría el riesgo de sobreajuste y el tiempo de entrenamiento. 128 es un tamaño común y efectivo para una primera capa oculta en problemas de clasificación de imágenes de esta escala, permitiendo la extracción de características de bajo nivel y la reducción de la dimensionalidad inicial de la entrada.\n","\n","*   **Segunda Capa Oculta (`hidden2`):**\n","    *   **Tamaño:** 64 neuronas.\n","    *   **Justificación:** Con 64 neuronas, esta capa actúa como un paso adicional para refinar las características aprendidas por la primera capa oculta, reduciendo aún más la dimensionalidad antes de la capa de salida. La disminución progresiva del número de neuronas en capas subsiguientes es una práctica común para concentrar la información más relevante y preparar la salida final, evitando al mismo tiempo el sobreajuste y manteniendo la eficiencia computacional.\n","\n","*   **Capa de Salida (`output_size`):**\n","    *   **Tamaño:** 24 neuronas.\n","    *   **Justificación:** El dataset ASL contiene 24 clases únicas (representando las letras del alfabeto inglés, excluyendo 'J' y 'Z', que requieren movimiento). Por lo tanto, la capa de salida debe tener 24 neuronas, una para cada clase posible, que producirán las puntuaciones (logits) antes de la aplicación de la función softmax para obtener las probabilidades de clase.\n","\n","### Justificación de las Decisiones de Diseño\n","\n","La elección de **dos capas ocultas** proporciona a la red la **profundidad** necesaria para aprender representaciones jerárquicas de las imágenes. Una sola capa oculta podría ser insuficiente para capturar la complejidad de las diferentes señales de ASL, mientras que una red mucho más profunda podría ser más difícil de entrenar y propensa a sobreajuste en un dataset de este tamaño. La progresión de 128 a 64 neuronas en las capas ocultas representa una **amplitud** decreciente, lo que ayuda a la red a comprimir y abstraer la información de manera eficiente. Este diseño es una arquitectura estándar para problemas de clasificación de imágenes con una complejidad moderada, buscando un equilibrio entre capacidad de aprendizaje y eficiencia. La inicialización de pesos con el método He (`np.sqrt(2./input_size)`) en las capas `Linear` es crucial para mitigar los problemas de gradientes desvanecidos o explosivos, especialmente en redes con capas ReLU, permitiendo un entrenamiento más estable y rápido."]},{"cell_type":"markdown","metadata":{"id":"5QmWLaNpW8J-"},"source":["## Elección y Justificación de Hiperparámetros\n","\n","Para el entrenamiento de nuestra Red Neuronal Profunda, hemos seleccionado cuidadosamente los siguientes hiperparámetros, buscando un equilibrio entre rendimiento, eficiencia y estabilidad del modelo.\n","\n","### Tasa de Aprendizaje (`learning_rate = 0.1`)\n","\n","*   **Función:** La tasa de aprendizaje determina el tamaño de los pasos que el optimizador toma en la dirección negativa del gradiente para actualizar los pesos del modelo. Un valor alto puede acelerar la convergencia pero corre el riesgo de sobrepasar el mínimo global, mientras que un valor bajo puede hacer que la convergencia sea muy lenta o quede atrapado en mínimos locales.\n","*   **Justificación:** Se eligió un `learning_rate` inicial de `0.1` para permitir que el modelo realice ajustes significativos en las primeras etapas del entrenamiento. Este valor es un punto de partida común que a menudo funciona bien con optimizadores basados en gradiente estocástico para problemas de clasificación de imágenes. Se espera que un `learning_rate` relativamente alto ayude a la red a explorar el espacio de pesos de manera más agresiva al principio. Si se observan oscilaciones en la pérdida o divergencia, se podría considerar una reducción o el uso de un programador de tasas de aprendizaje.\n","\n","### Épocas (`epochs = 20`)\n","\n","*   **Función:** Una época representa un ciclo completo a través de todo el conjunto de datos de entrenamiento. El número de épocas define cuántas veces el modelo verá y aprenderá de cada ejemplo de entrenamiento.\n","*   **Justificación:** Se establecieron `20` épocas como un valor inicial. Este número es un compromiso para permitir que el modelo tenga suficientes oportunidades para aprender patrones complejos del dataset ASL sin incurrir en un tiempo de entrenamiento excesivamente largo que podría llevar a un sobreajuste prematuro en el conjunto de validación o a un uso ineficiente de recursos computacionales. Observando la precisión de validación (`Val Acc`) durante el entrenamiento, se buscará determinar si se necesita un mayor número de épocas para una mejor convergencia o si un menor número es suficiente antes de que el rendimiento empiece a estancarse o decaer.\n","\n","### Tamaño del Lote (`batch_size = 64`)\n","\n","*   **Función:** El tamaño del lote (`batch_size`) se refiere al número de muestras de entrenamiento procesadas antes de que los pesos del modelo sean actualizados. Lotes más grandes proporcionan una estimación más precisa del gradiente global, mientras que lotes más pequeños introducen más ruido pero pueden ayudar a escapar de mínimos locales y a generalizar mejor.\n","*   **Justificación:** Un `batch_size` de `64` es una elección popular que ofrece un buen equilibrio. Es lo suficientemente grande como para obtener una estimación de gradiente estable en cada iteración, lo que ayuda a una convergencia más suave y eficiente computacionalmente en comparación con lotes muy pequeños. Al mismo tiempo, es lo suficientemente pequeño como para introducir cierta aleatoriedad y evitar la convergencia a mínimos locales no óptimos, un problema que a veces surge con lotes muy grandes. Este tamaño también se considera eficiente en términos de utilización de memoria y paralelización en hardware moderno."]},{"cell_type":"markdown","metadata":{"id":"dDPAxwWI8l6u"},"source":["### Test your model on Random data from your test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFZ4KXaE8l6u","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1770002895289,"user_tz":300,"elapsed":73,"user":{"displayName":"Juan Carlos Gaibor","userId":"16350272554692264517"}},"outputId":"509f9e12-e522-4735-838f-cc6a4c9f8705"},"outputs":[{"output_type":"stream","name":"stdout","text":["el valor predicho es: s el valor real es:s\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["idx = np.random.randint(len(y_test))\n","plot_number(x_test[idx].reshape(28,28))\n","pred = model.predict(x_test[idx].reshape(-1, 1))\n","print(f'el valor predicho es: {alphabet[pred]} el valor real es:{alphabet[y_test[idx]]}')"]},{"cell_type":"markdown","source":["### Evaluar la precision del modelo"],"metadata":{"id":"HqeZphascpF_"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae185026","executionInfo":{"status":"ok","timestamp":1770002895354,"user_tz":300,"elapsed":60,"user":{"displayName":"Juan Carlos Gaibor","userId":"16350272554692264517"}},"outputId":"13d1af95-2b46-49ae-8ae8-8ac11f2949dc"},"source":["print(\"Evaluando el modelo en el conjunto de prueba...\")\n","# Obtener predicciones del modelo para el conjunto de prueba\n","# Transponemos x_test para que tenga la forma (features, num_samples) que espera el modelo\n","test_preds = model.predict(x_test.T)\n","\n","# Calcular la precisión comparando las predicciones con las etiquetas reales\n","test_acc = np.mean(test_preds == y_test)\n","\n","# Imprimir la precisión del modelo en el conjunto de prueba\n","print(f\"Precisión del modelo en el conjunto de prueba: {test_acc:.4f}\")\n","\n","# Comprobar si se cumple el criterio del 70% de precisión\n","if test_acc >= 0.70:\n","    print(\"¡El modelo ha superado el umbral del 70% de precisión en el conjunto de prueba!\")\n","else:\n","    print(\"El modelo no alcanzó el umbral del 70% de precisión en el conjunto de prueba.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluando el modelo en el conjunto de prueba...\n","Precisión del modelo en el conjunto de prueba: 0.7783\n","¡El modelo ha superado el umbral del 70% de precisión en el conjunto de prueba!\n"]}]},{"cell_type":"markdown","metadata":{"id":"564aaf53"},"source":["## Análisis del Rendimiento del Modelo\n","\n","El modelo de red neuronal profunda entrenado para el dataset ASL ha demostrado un rendimiento prometedor, superando el umbral mínimo de precisión del 70% establecido en los criterios de evaluación. A continuación, se presenta un análisis detallado:\n","\n","### Precisión en el Conjunto de Prueba\n","\n","*   **Precisión Final:** `0.7783` (aproximadamente 77.83%)\n","*   **Cumplimiento del Criterio:** El modelo **ha superado** el umbral del 70% de precisión en el conjunto de prueba, lo cual es un indicador positivo de su capacidad de generalización a datos no vistos.\n","\n","### Análisis de las Tendencias de Entrenamiento\n","\n","Durante las 20 épocas de entrenamiento, se observaron las siguientes tendencias:\n","\n","*   **Pérdida de Entrenamiento (Loss):** La pérdida de entrenamiento (`Loss`) disminuyó consistentemente a lo largo de las épocas, pasando de un valor inicial de `2.7246` a `0.0129` en la última época. Esta tendencia indica que el modelo está aprendiendo eficazmente del conjunto de entrenamiento y ajustando sus pesos para minimizar el error.\n","\n","*   **Precisión de Validación (Val Acc):** La precisión en el conjunto de validación (`Val Acc`) mostró una tendencia general al alza, aunque con algunas fluctuaciones. Inició en `0.3385` y alcanzó `0.7939` al final del entrenamiento. Las fluctuaciones, como caídas en la precisión en algunas épocas (e.g., Época 2, 7, 11, 17), podrían indicar momentos donde el modelo se acercó a un mínimo local, experimentó con un valor de `learning_rate` quizás agresivo o estuvo al borde de sobreajustar en el mini-batch particular que causó una actualización desfavorable de los pesos. A pesar de estas oscilaciones, la tendencia final fue positiva y se logró una buena precisión.\n","\n","### Insights y Limitaciones\n","\n","*   **Rendimiento Sólido:** La arquitectura de red con dos capas ocultas y las funciones de activación ReLU, junto con la inicialización de He, parece ser adecuada para este problema de clasificación de imágenes. El modelo logra capturar características distintivas de las imágenes de señales ASL.\n","*   **Sensibilidad a Hiperparámetros:** Las fluctuaciones en la precisión de validación sugieren que el modelo podría ser sensible a la tasa de aprendizaje o que la elección del `batch_size` podría tener un impacto en la estabilidad de la convergencia. Aunque `0.1` es una tasa de aprendizaje alta, la red logró converger. Pequeñas inconsistencias en el conjunto de validación podrían también ser una causa.\n","*   **Posible Sobreajuste:** Aunque la precisión de validación es buena, el hecho de que la pérdida de entrenamiento disminuye drásticamente mientras la precisión de validación tiene altibajos, podría ser una señal temprana de que el modelo está empezando a sobreajustar a los datos de entrenamiento en algunas épocas, aunque no de manera severa en la precisión final.\n","\n","### Sugerencias para Futuras Mejoras\n","\n","Para optimizar aún más el rendimiento del modelo y abordar las limitaciones observadas, se podrían considerar las siguientes mejoras:\n","\n","1.  **Ajuste de la Tasa de Aprendizaje:** Implementar un programador de tasas de aprendizaje (learning rate scheduler) que disminuya `lr` con el tiempo o al estancarse la precisión de validación. Esto podría ayudar a suavizar la convergencia y alcanzar un mínimo más profundo.\n","2.  **Regularización:** Añadir técnicas de regularización como Dropout o regularización L1/L2 a las capas `Linear` para mitigar el sobreajuste, especialmente si se planea aumentar la complejidad del modelo o el número de épocas.\n","3.  **Aumento de Datos (Data Augmentation):** Aplicar transformaciones a las imágenes de entrenamiento (rotación, zoom, volteo, etc.) para aumentar la diversidad del conjunto de datos y mejorar la robustez del modelo.\n","4.  **Optimización de Arquitectura:** Experimentar con un mayor número de neuronas en las capas ocultas o añadir una capa oculta adicional para ver si el modelo puede aprender representaciones más ricas, siempre vigilando el sobreajuste.\n","5.  **Validación Cruzada:** Para una evaluación más robusta, se podría implementar la validación cruzada k-fold para obtener una estimación más fiable de la capacidad de generalización del modelo."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}